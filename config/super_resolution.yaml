MODEL:


TRAIN:
  pretrained_trans: './pretrain_transformer.pth'
  train_data_dir: [
    './dataset/TextZoom/train1',
    './dataset/TextZoom/train2',
  ]
  batch_size: 48
  width: 128
  height: 32
  epochs: 500
  cuda: True
  ngpu: 2
  workers: 0
  # resume: './LEMMA/ckpt_copy/demo/checkpoint.pth'
  resume: './ckpt_2/demo/model_best_acc_0.pth'
  ckpt_dir: './ckpt/with_test'
  voc_type: 'all' #'digits lower upper all'
  saveInterval: 200
  displayInterval: 50 #display loss
  adadelta: False
  lr: 0.001
  adam: True
  optimizer: "Adam"
  beta1: 0.5
  manualSeed: 1234
  max_len: 100
  keep_ratio: False
  down_sample_scale: 2

  VAL:
    val_data_dir: [
#        './dataset/IC15',
#        './dataset/CUTE80',
#        './dataset/SVTP',
#        './dataset/SVT',
      './dataset/TextZoom/test/easy',
      './dataset/TextZoom/test/medium',
      './dataset/TextZoom/test/hard',
    ]
    n_vis: 10
    vis_dir: 'demo'
    valInterval: 400
    rec_pretrained: './dataset/TextZoom/demo.pth.tar'
    moran_pretrained: './dataset/TextZoom/moran.pth'
    crnn_pretrained: './dataset/TextZoom/crnn.pth'

TEST:
  checkpoint: ''
  test_data_dir: [
  ]

CONVERT:
  image_dir:
  lmdb_dir:
  n_convert: 10


PositionAware:
  dataset_max_length: 25
  dataset_charset_path: './dataset/charset_36.txt'
  model_vision_attention_mode: 'nearest'
  vision: {
    checkpoint: './workdir/pretrain-vision-model/best-pretrain-vision-model.pth',
    loss_weight: 1.,
    attention: 'position',
    backbone: 'transformer',
    backbone_ln: 3,
    d_model: 512
  }
  language: {
    checkpoint: './workdir/pretrain-language-model/pretrain-language-model.pth',
    num_layers: 4,
    loss_weight: 1.,
    detach: True,
    use_self_attn: False
  }


ABINet:
  dataset_max_length: 25
  dataset_charset_path: './dataset/charset_36.txt'
  model_vision_attention_mode: 'nearest'
  full_ckpt: './workdir/train-abinet/best-train-abinet.pth'
  vision: {
    checkpoint: './workdir/pretrain-vision-model/best-pretrain-vision-model.pth',
    loss_weight: 1.,
    attention: 'position',
    backbone: 'transformer',
    backbone_ln: 3,
    d_model: 512
  }
  language: {
    checkpoint: './workdir/pretrain-language-model/pretrain-language-model.pth',
    num_layers: 4,
    loss_weight: 1.,
    detach: True,
    use_self_attn: False
  }



MATRN:
  dataset_charset_path: './dataset/charset_36.txt'
  dataset_max_length: 25
  model_vision_attention_mode: 'nearest'
  full_ckpt: './pretrained/ABINet-pretrained/best-train-matrn.pth'
  vision: {
    checkpoint: ,
    attention: 'position',
    backbone: 'transformer',
    backbone_ln: 3,
    d_model: 512
  }
  language: {
    checkpoint: ,
    num_layers: 4,
    detach: True,
    use_self_attn: False
  }

PARSeq:
  full_ckpt: './pretrained/PARSeq.pth'
  img_size: [32,128]
  patch_size: [4,8]
  embed_dim: 384
  enc_depth: 12
  enc_num_heads: 6
  enc_mlp_ratio: 4

  self.max_label_length: 25
  self.decode_ar: True
  self.refine_iters: 1

  dec_num_heads: 12
  dec_mlp_ratio: 4
  dropout: 0.1
  dec_depth: 1
  perm_num: 6
  perm_mirrored: True
  max_label_length: 25


