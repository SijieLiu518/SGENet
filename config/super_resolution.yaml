MODEL:


TRAIN:
  pretrained_trans: './workdir/pretrain_transformer.pth'
  train_data_dir: [
    './dataset/TextZoom/train1',
    './dataset/TextZoom/train2',
  ]
  batch_size: 48
  width: 128
  height: 32
  epochs: 500
  cuda: True
  ngpu: 2
  workers: 0
  resume: './ckpt_2/demo/model_best_acc_0.pth'
  ckpt_dir: './ckpt/with_test'
  voc_type: 'all' #'digits lower upper all'
  saveInterval: 200
  displayInterval: 50 #display loss
  adadelta: False
  lr: 0.001
  adam: True
  optimizer: "Adam"
  beta1: 0.5
  manualSeed: 1234
  max_len: 100
  keep_ratio: False
  down_sample_scale: 2

  VAL:
    val_data_dir: [
      './dataset/TextZoom/test/easy',
      './dataset/TextZoom/test/medium',
      './dataset/TextZoom/test/hard',
    ]
    n_vis: 10
    vis_dir: 'demo'
    valInterval: 400
    rec_pretrained: './dataset/TextZoom/demo.pth.tar'
    moran_pretrained: './dataset/TextZoom/moran.pth'
    crnn_pretrained: './dataset/TextZoom/crnn.pth'

TEST:
  checkpoint: ''
  test_data_dir: [
  ]

CONVERT:
  image_dir:
  lmdb_dir:
  n_convert: 10


PositionAware:
  dataset_max_length: 25
  dataset_charset_path: './dataset/charset_36.txt'
  model_vision_attention_mode: 'nearest'
  vision: {
    checkpoint: './workdir/pretrain-vision-model/best-pretrain-vision-model.pth',
    loss_weight: 1.,
    attention: 'position',
    backbone: 'transformer',
    backbone_ln: 3,
    d_model: 512
  }
  language: {
    checkpoint: './workdir/pretrain-language-model/pretrain-language-model.pth',
    num_layers: 4,
    loss_weight: 1.,
    detach: True,
    use_self_attn: False
  }
